{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'regressors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformula\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmf\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mregressors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'regressors'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import googlemaps\n",
    "import folium\n",
    "from folium.plugins import HeatMap, HeatMapWithTime\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from regressors import stats\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publishing_Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Cuisine_Cleaned</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>CriticsPick</th>\n",
       "      <th>Rank</th>\n",
       "      <th>...</th>\n",
       "      <th>nta2020</th>\n",
       "      <th>ntaname</th>\n",
       "      <th>ntaabbrev</th>\n",
       "      <th>ntatype</th>\n",
       "      <th>cdta2020</th>\n",
       "      <th>cdtaname</th>\n",
       "      <th>shape_leng</th>\n",
       "      <th>shape_area</th>\n",
       "      <th>isNYC</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Wichcraft</td>\n",
       "      <td>PETER MEEHAN</td>\n",
       "      <td>Sept. 7, 2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>American, Sandwiches</td>\n",
       "      <td>American</td>\n",
       "      <td>Midtown South</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MN0502</td>\n",
       "      <td>Midtown-Times Square</td>\n",
       "      <td>Mdtwn_TmSq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MN05</td>\n",
       "      <td>MN05 Midtown-Flatiron-Union Square (CD 5 Appro...</td>\n",
       "      <td>21258.40137</td>\n",
       "      <td>2.455251e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Chairs</td>\n",
       "      <td>ERIC ASIMOV</td>\n",
       "      <td>Oct. 18, 1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$</td>\n",
       "      <td>Russian</td>\n",
       "      <td>Russian</td>\n",
       "      <td>SoHo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MN0201</td>\n",
       "      <td>SoHo-Little Italy-Hudson Square</td>\n",
       "      <td>SoHo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MN02</td>\n",
       "      <td>MN02 Greenwich Village-SoHo (CD 2 Equivalent)</td>\n",
       "      <td>18577.11174</td>\n",
       "      <td>1.291676e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15 East</td>\n",
       "      <td>FRANK BRUNI</td>\n",
       "      <td>11-Jul-07</td>\n",
       "      <td>2 star</td>\n",
       "      <td>$$$$</td>\n",
       "      <td>Japanese, Sushi</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Union Square</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MN0501</td>\n",
       "      <td>Midtown South-Flatiron-Union Square</td>\n",
       "      <td>MdtwnSth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MN05</td>\n",
       "      <td>MN05 Midtown-Flatiron-Union Square (CD 5 Appro...</td>\n",
       "      <td>18800.76597</td>\n",
       "      <td>1.487811e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188 Bakery Cuchifritos</td>\n",
       "      <td>PETE WELLS</td>\n",
       "      <td>2-Apr-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>Puerto Rican, Dominican</td>\n",
       "      <td>Latin American</td>\n",
       "      <td>Fordham Heights</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BX0503</td>\n",
       "      <td>Fordham Heights</td>\n",
       "      <td>FrdhmHts</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BX05</td>\n",
       "      <td>BX05 Morris Heights-Mount Hope (CD 5 Approxima...</td>\n",
       "      <td>12917.28009</td>\n",
       "      <td>7.379040e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd City</td>\n",
       "      <td>LIGAYA MISHAN</td>\n",
       "      <td>Sept. 15, 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$</td>\n",
       "      <td>Philippine</td>\n",
       "      <td>Filipino</td>\n",
       "      <td>West Village</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MN0203</td>\n",
       "      <td>West Village</td>\n",
       "      <td>WstVlg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MN02</td>\n",
       "      <td>MN02 Greenwich Village-SoHo (CD 2 Equivalent)</td>\n",
       "      <td>23882.33924</td>\n",
       "      <td>1.441774e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>Zaytoons</td>\n",
       "      <td>ERIC ASIMOV</td>\n",
       "      <td>7-Jul-99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>Carroll Gardens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BK0601</td>\n",
       "      <td>Carroll Gardens-Cobble Hill-Gowanus-Red Hook</td>\n",
       "      <td>CrrllGrdns</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BK06</td>\n",
       "      <td>BK06 Park Slope-Carroll Gardens (CD 6 Approxim...</td>\n",
       "      <td>67164.87096</td>\n",
       "      <td>6.081178e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Zizi Limona</td>\n",
       "      <td>LIGAYA MISHAN</td>\n",
       "      <td>Jan. 10, 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$</td>\n",
       "      <td>Mediterranean, Middle Eastern</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BK0102</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>Wllmsbrg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BK01</td>\n",
       "      <td>BK01 Williamsburg-Greenpoint (CD 1 Equivalent)</td>\n",
       "      <td>28098.02702</td>\n",
       "      <td>2.885431e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>Zoma</td>\n",
       "      <td>PETER MEEHAN</td>\n",
       "      <td>Jan. 10, 2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$</td>\n",
       "      <td>African, Moroccan</td>\n",
       "      <td>African</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MN1001</td>\n",
       "      <td>Harlem (South)</td>\n",
       "      <td>Hrlm_S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MN10</td>\n",
       "      <td>MN10 Harlem (CD 10 Equivalent)</td>\n",
       "      <td>16624.46279</td>\n",
       "      <td>1.444123e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Zum Stammtisch</td>\n",
       "      <td>PETE WELLS</td>\n",
       "      <td>2-Apr-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$</td>\n",
       "      <td>German</td>\n",
       "      <td>German</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>QN0503</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>Glndl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>QN05</td>\n",
       "      <td>QN05 Ridgewood-Maspeth-Middle Village (CD 5 Ap...</td>\n",
       "      <td>41557.49038</td>\n",
       "      <td>3.000644e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>Ãpizz</td>\n",
       "      <td>ERIC ASIMOV</td>\n",
       "      <td>Sept. 20, 2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$$$</td>\n",
       "      <td>Italian, Pizza</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Lower East Side</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>MN0302</td>\n",
       "      <td>Lower East Side</td>\n",
       "      <td>LES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MN03</td>\n",
       "      <td>MN03 Lower East Side-Chinatown (CD 3 Equivalent)</td>\n",
       "      <td>19890.88544</td>\n",
       "      <td>1.647319e+07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1251 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Restaurant_name         Author Publishing_Date  Rating Price  \\\n",
       "0                 'Wichcraft   PETER MEEHAN   Sept. 7, 2005     NaN     $   \n",
       "1                  12 Chairs    ERIC ASIMOV   Oct. 18, 1996     NaN    $$   \n",
       "2                    15 East    FRANK BRUNI       11-Jul-07  2 star  $$$$   \n",
       "3     188 Bakery Cuchifritos     PETE WELLS        2-Apr-24     NaN     $   \n",
       "4                   2nd City  LIGAYA MISHAN  Sept. 15, 2016     NaN    $$   \n",
       "...                      ...            ...             ...     ...   ...   \n",
       "1288                Zaytoons    ERIC ASIMOV        7-Jul-99     NaN     $   \n",
       "1289             Zizi Limona  LIGAYA MISHAN   Jan. 10, 2013     NaN    $$   \n",
       "1290                    Zoma   PETER MEEHAN   Jan. 10, 2007     NaN    $$   \n",
       "1291          Zum Stammtisch     PETE WELLS        2-Apr-24     NaN    $$   \n",
       "1292                  Ãpizz    ERIC ASIMOV  Sept. 20, 2002     NaN   $$$   \n",
       "\n",
       "                            Cuisine Cuisine_Cleaned     Neighborhood  \\\n",
       "0              American, Sandwiches        American    Midtown South   \n",
       "1                           Russian         Russian             SoHo   \n",
       "2                   Japanese, Sushi        Japanese     Union Square   \n",
       "3           Puerto Rican, Dominican  Latin American  Fordham Heights   \n",
       "4                        Philippine        Filipino     West Village   \n",
       "...                             ...             ...              ...   \n",
       "1288                 Middle Eastern  Middle Eastern  Carroll Gardens   \n",
       "1289  Mediterranean, Middle Eastern   Mediterranean     Williamsburg   \n",
       "1290              African, Moroccan         African           Harlem   \n",
       "1291                         German          German         Glendale   \n",
       "1292                 Italian, Pizza         Italian  Lower East Side   \n",
       "\n",
       "      CriticsPick  Rank  ...  nta2020  \\\n",
       "0             0.0   0.0  ...   MN0502   \n",
       "1             0.0   0.0  ...   MN0201   \n",
       "2             0.0   0.0  ...   MN0501   \n",
       "3             0.0  86.0  ...   BX0503   \n",
       "4             0.0   0.0  ...   MN0203   \n",
       "...           ...   ...  ...      ...   \n",
       "1288          0.0   0.0  ...   BK0601   \n",
       "1289          1.0   0.0  ...   BK0102   \n",
       "1290          0.0   0.0  ...   MN1001   \n",
       "1291          0.0  97.0  ...   QN0503   \n",
       "1292          0.0   0.0  ...   MN0302   \n",
       "\n",
       "                                           ntaname   ntaabbrev ntatype  \\\n",
       "0                             Midtown-Times Square  Mdtwn_TmSq     0.0   \n",
       "1                  SoHo-Little Italy-Hudson Square        SoHo     0.0   \n",
       "2              Midtown South-Flatiron-Union Square    MdtwnSth     0.0   \n",
       "3                                  Fordham Heights    FrdhmHts     0.0   \n",
       "4                                     West Village      WstVlg     0.0   \n",
       "...                                            ...         ...     ...   \n",
       "1288  Carroll Gardens-Cobble Hill-Gowanus-Red Hook  CrrllGrdns     0.0   \n",
       "1289                                  Williamsburg    Wllmsbrg     0.0   \n",
       "1290                                Harlem (South)      Hrlm_S     0.0   \n",
       "1291                                      Glendale       Glndl     0.0   \n",
       "1292                               Lower East Side         LES     0.0   \n",
       "\n",
       "     cdta2020                                           cdtaname   shape_leng  \\\n",
       "0        MN05  MN05 Midtown-Flatiron-Union Square (CD 5 Appro...  21258.40137   \n",
       "1        MN02      MN02 Greenwich Village-SoHo (CD 2 Equivalent)  18577.11174   \n",
       "2        MN05  MN05 Midtown-Flatiron-Union Square (CD 5 Appro...  18800.76597   \n",
       "3        BX05  BX05 Morris Heights-Mount Hope (CD 5 Approxima...  12917.28009   \n",
       "4        MN02      MN02 Greenwich Village-SoHo (CD 2 Equivalent)  23882.33924   \n",
       "...       ...                                                ...          ...   \n",
       "1288     BK06  BK06 Park Slope-Carroll Gardens (CD 6 Approxim...  67164.87096   \n",
       "1289     BK01     BK01 Williamsburg-Greenpoint (CD 1 Equivalent)  28098.02702   \n",
       "1290     MN10                     MN10 Harlem (CD 10 Equivalent)  16624.46279   \n",
       "1291     QN05  QN05 Ridgewood-Maspeth-Middle Village (CD 5 Ap...  41557.49038   \n",
       "1292     MN03   MN03 Lower East Side-Chinatown (CD 3 Equivalent)  19890.88544   \n",
       "\n",
       "        shape_area  isNYC  Status  \n",
       "0     2.455251e+07    1.0    Open  \n",
       "1     1.291676e+07    1.0    Open  \n",
       "2     1.487811e+07    1.0    Open  \n",
       "3     7.379040e+06    1.0    Open  \n",
       "4     1.441774e+07    1.0    Open  \n",
       "...            ...    ...     ...  \n",
       "1288  6.081178e+07    1.0    Open  \n",
       "1289  2.885431e+07    1.0    Open  \n",
       "1290  1.444123e+07    1.0    Open  \n",
       "1291  3.000644e+07    1.0    Open  \n",
       "1292  1.647319e+07    1.0    Open  \n",
       "\n",
       "[1251 rows x 43 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/skareti/Desktop/Independent Study/NYTRestaurantReviews/data/AnalysisDataset.csv', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi Square Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         CHI SQUARE TESTING\n",
      "Chi-Square Test for Cuisine:\n",
      "Chi2 Stat: 166.29435069959234 P-value: 4.634449204479245e-05\n",
      "Result: Statistically significant relationship found.\n",
      "Chi-Square Test for Neighborhood:\n",
      "Chi2 Stat: 230.25017982002018 P-value: 1.0603678020464574e-07\n",
      "Result: Statistically significant relationship found.\n",
      "Chi-Square Test for Price:\n",
      "Chi2 Stat: 13.05759006109797 P-value: 0.004513704428716706\n",
      "Result: Statistically significant relationship found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"                         CHI SQUARE TESTING\")\n",
    "# Contingency table for Cuisine vs CriticsPick\n",
    "table_cuisine = pd.crosstab(df['Cuisine_Cleaned'], df['top100_2024'])\n",
    "\n",
    "# Contingency table for Neighborhood vs CriticsPick\n",
    "table_neighborhood = pd.crosstab(df['Neighborhood'], df['top100_2024'])\n",
    "\n",
    "table_price = pd.crosstab(df['Price'], df['top100_2024'])\n",
    "\n",
    "\n",
    "# Chi-Square Test for Cuisine\n",
    "chi2_cuisine, p_cuisine, dof_cuisine, expected_cuisine = chi2_contingency(table_cuisine)\n",
    "print(\"Chi-Square Test for Cuisine:\")\n",
    "print(\"Chi2 Stat:\", chi2_cuisine, \"P-value:\", p_cuisine)\n",
    "if p_cuisine < 0.05:\n",
    "    print(\"Result: Statistically significant relationship found.\")\n",
    "else:\n",
    "    print(\"Result: No statistically significant relationship found.\")\n",
    "\n",
    "# Chi-Square Test for Neighborhood\n",
    "chi2_neighborhood, p_neighborhood, dof_neighborhood, expected_neighborhood = chi2_contingency(table_neighborhood)\n",
    "print(\"Chi-Square Test for Neighborhood:\")\n",
    "print(\"Chi2 Stat:\", chi2_neighborhood, \"P-value:\", p_neighborhood)\n",
    "if p_neighborhood < 0.05:\n",
    "    print(\"Result: Statistically significant relationship found.\")\n",
    "else:\n",
    "    print(\"Result: No statistically significant relationship found.\")\n",
    "\n",
    "# Chi-Square Test for Price\n",
    "chi2_price, p_price, dof_price, expected_price = chi2_contingency(table_price)\n",
    "print(\"Chi-Square Test for Price:\")\n",
    "print(\"Chi2 Stat:\", chi2_price, \"P-value:\", p_price)\n",
    "if p_price < 0.05:\n",
    "    print(\"Result: Statistically significant relationship found.\")\n",
    "else:\n",
    "    print(\"Result: No statistically significant relationship found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it appears that there are significant relationships between a Restaurant's Cuisine, Neighborhood, and Price level and being in the NYT top 100 list. Let's carry out a series of Post-Hoc Analyses to further investigate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Hoc Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Residuals for Cuisine:\n",
      " top100_2024             0.0       1.0\n",
      "Cuisine_Cleaned                      \n",
      "Afghan             0.145849 -0.492145\n",
      "African            0.385881 -1.302092\n",
      "Albanian          -0.958783  3.235255\n",
      "American           0.202581 -0.683575\n",
      "Asian              0.315071 -1.063154\n",
      "...                     ...       ...\n",
      "Vegan             -0.456321  1.539779\n",
      "Vegan, Vegetarian -0.958783  3.235255\n",
      "Vegetarian        -0.456321  1.539779\n",
      "Vietnamese         0.143362 -0.483751\n",
      "Wine Bars          0.119085 -0.401834\n",
      "\n",
      "[102 rows x 2 columns]\n",
      "Significant Standardized Residuals:\n",
      " top100_2024                 0.0       1.0\n",
      "Cuisine_Cleaned                          \n",
      "Albanian                    NaN  3.235255\n",
      "English, French             NaN  2.086753\n",
      "French                      NaN  2.670493\n",
      "Israeli                     NaN  3.235255\n",
      "Korean                      NaN  2.098198\n",
      "Nigerian                    NaN  3.235255\n",
      "Scandinavian                NaN  2.951115\n",
      "Serbian                     NaN  2.951115\n",
      "Small Plates                NaN  3.235255\n",
      "Trinidadian and Tobagonian  NaN  3.235255\n",
      "Uyghur                      NaN  3.235255\n",
      "Vegan, Vegetarian           NaN  3.235255\n"
     ]
    }
   ],
   "source": [
    "# Create a contingency table for Cuisine vs. Top 100\n",
    "contingency_table_cuisine = pd.crosstab(df['Cuisine_Cleaned'], df['top100_2024'])\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table_cuisine)\n",
    "\n",
    "# Calculate standardized residuals\n",
    "residuals = (contingency_table_cuisine - expected) / np.sqrt(expected)\n",
    "print(\"Standardized Residuals for Cuisine:\\n\", residuals)\n",
    "\n",
    "\n",
    "# Define a significance threshold (e.g., 1.96 for 95% confidence level)\n",
    "significance_threshold = 1.96\n",
    "\n",
    "# Filter significant residuals\n",
    "significant_residuals = residuals[\n",
    "    (residuals.abs() > significance_threshold)\n",
    "]\n",
    "\n",
    "# Drop rows that don't have any significant residuals\n",
    "significant_residuals = significant_residuals.dropna(how='all')\n",
    "\n",
    "print(\"Significant Standardized Residuals:\\n\", significant_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Residuals for Neighborhood:\n",
      " top100_2024              0.0       1.0\n",
      "Neighborhood                          \n",
      "Astoria             0.092989 -0.314381\n",
      "Battery Park City   0.083896 -0.283638\n",
      "Bay Ridge          -0.172184  0.582124\n",
      "Bayside             0.118647 -0.401125\n",
      "Bedford-Stuyvesant  0.251688 -0.850914\n",
      "...                      ...       ...\n",
      "Williamsburg       -0.130988  0.442848\n",
      "Windsor Terrace     0.118647 -0.401125\n",
      "Woodside            0.324928 -1.098525\n",
      "Woodstock          -0.958931  3.241982\n",
      "Yorkville           0.083896 -0.283638\n",
      "\n",
      "[130 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a contingency table for Cuisine vs. Top 100\n",
    "contingency_table_cuisine = pd.crosstab(df['Neighborhood'], df['top100_2024'])\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table_cuisine)\n",
    "\n",
    "# Calculate standardized residuals\n",
    "residuals = (contingency_table_cuisine - expected) / np.sqrt(expected)\n",
    "print(\"Standardized Residuals for Neighborhood:\\n\", residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Residuals for Price:\n",
      " top100_2024       0.0       1.0\n",
      "Price                          \n",
      "$            0.528136 -1.781332\n",
      "$$           0.076382 -0.257626\n",
      "$$$         -0.003268  0.011022\n",
      "$$$$        -0.877657  2.960220\n"
     ]
    }
   ],
   "source": [
    "# Create a contingency table for Cuisine vs. Top 100\n",
    "contingency_table_cuisine = pd.crosstab(df['Price'], df['top100_2024'])\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table_cuisine)\n",
    "\n",
    "# Calculate standardized residuals\n",
    "residuals = (contingency_table_cuisine - expected) / np.sqrt(expected)\n",
    "print(\"Standardized Residuals for Price:\\n\", residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# # Pairwise comparisons for Cuisine\n",
    "# cuisines = df['Cuisine'].unique()\n",
    "# pairs = list(combinations(cuisines, 2))\n",
    "# p_values = []\n",
    "\n",
    "# for pair in pairs:\n",
    "#     sub_table = df[df['Cuisine'].isin(pair)]\n",
    "#     contingency_table_pair = pd.crosstab(sub_table['Cuisine'], sub_table['top100_2024'])\n",
    "#     chi2, p, dof, expected = chi2_contingency(contingency_table_pair)\n",
    "#     p_values.append(p)\n",
    "\n",
    "# # Apply Bonferroni correction\n",
    "# reject, pvals_corrected, _, _ = multipletests(p_values, method='bonferroni')\n",
    "# results = pd.DataFrame({\n",
    "#     'Pair': pairs,\n",
    "#     'P-Value': p_values,\n",
    "#     'Corrected P-Value': pvals_corrected,\n",
    "#     'Reject Null Hypothesis': reject\n",
    "# })\n",
    "# print(\"Pairwise Comparisons for Cuisine:\\n\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       American, Sandwiches\n",
      "1                    Russian\n",
      "2            Japanese, Sushi\n",
      "3    Puerto Rican, Dominican\n",
      "4                 Philippine\n",
      "Name: Cuisine, dtype: object\n",
      "Top 20 Cuisines: ['American', 'Italian', 'Japanese', 'Chinese', 'French', 'Mexican', 'Latin American', 'Thai', 'Middle Eastern', 'Korean', 'Indian', 'Steak Houses', 'Seafood', 'Caribbean', 'Spanish', 'African', 'Mediterranean', 'Bakery/Caf\\x8e', 'Vietnamese', 'Asian', 'Filipino', 'Greek', 'English', 'Turkish', 'Tibetan', 'Malaysian', 'Deli', 'German', 'Taiwanese', 'Russian', 'Moroccan', 'Pizza', 'Burmese', 'Brazilian', 'European', 'Barbecue', 'Vegan', 'Scandinavian', 'Indonesian', 'Vegetarian', 'Kosher', 'Eastern European', 'Serbian', 'Irish', 'Ethiopian', 'Bangladeshi', 'Austrian', 'Portuguese', 'Afghan', 'Cafes']\n",
      "  Cuisine_Cleaned     Top_Cuisine\n",
      "0        American        American\n",
      "1         Russian         Russian\n",
      "2        Japanese        Japanese\n",
      "3  Latin American  Latin American\n",
      "4        Filipino        Filipino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/rlq1jslj0qsdfph0bh6cp1mc0000gn/T/ipykernel_62940/1895630711.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Top_Cuisine'] = df_filtered['Cuisine_Cleaned'].apply(lambda x: extract_top_cuisines(x, top_cuisines))\n"
     ]
    }
   ],
   "source": [
    "# Convert all values in the 'Cuisine' column to strings and replace NaN with an empty string\n",
    "df['Cuisine'] = df['Cuisine'].astype(str).fillna('')\n",
    "\n",
    "# Check the first few rows to confirm the conversion\n",
    "print(df['Cuisine'].head())\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Split cuisine combinations and count individual cuisines\n",
    "cuisine_counter = Counter()\n",
    "\n",
    "for cuisines in df['Cuisine_Cleaned']:\n",
    "    for cuisine in cuisines.split(', '):\n",
    "        cuisine_counter[cuisine] += 1\n",
    "\n",
    "# Get the top 20 most common cuisines\n",
    "top_cuisines = [cuisine for cuisine, _ in cuisine_counter.most_common(50)]\n",
    "\n",
    "print(\"Top 20 Cuisines:\", top_cuisines)\n",
    "\n",
    "\n",
    "# Function to check if a row's cuisines contain any of the top cuisines\n",
    "def contains_top_cuisine(cuisine_list, top_cuisines):\n",
    "    return any(cuisine in cuisine_list.split(', ') for cuisine in top_cuisines)\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_filtered = df[df['Cuisine_Cleaned'].apply(lambda x: contains_top_cuisine(x, top_cuisines))]\n",
    "\n",
    "# Optionally, create a new column with only the top cuisines for clarity\n",
    "def extract_top_cuisines(cuisine_list, top_cuisines):\n",
    "    return ', '.join([cuisine for cuisine in cuisine_list.split(', ') if cuisine in top_cuisines])\n",
    "\n",
    "df_filtered['Top_Cuisine'] = df_filtered['Cuisine_Cleaned'].apply(lambda x: extract_top_cuisines(x, top_cuisines))\n",
    "\n",
    "print(df_filtered[['Cuisine_Cleaned', 'Top_Cuisine']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280513\n",
      "         Iterations: 15\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:            top100_2024   No. Observations:                 1251\n",
      "Model:                          Logit   Df Residuals:                     1249\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Wed, 14 Aug 2024   Pseudo R-squ.:               0.0001726\n",
      "Time:                        20:31:23   Log-Likelihood:                -350.92\n",
      "converged:                       True   LL-Null:                       -350.98\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.7278\n",
      "================================================================================================\n",
      "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                       -2.3771      0.188    -12.661      0.000      -2.745      -2.009\n",
      "C(Wealthy_Neighborhood)[T.1]    -0.0787      0.225     -0.349      0.727      -0.520       0.363\n",
      "================================================================================================\n",
      "Odds Ratios for Top Cuisine:\n",
      " Intercept                       0.092817\n",
      "C(Wealthy_Neighborhood)[T.1]    0.924313\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "wealthy_neighborhoods = [\n",
    "    'Hudson Yards', 'SoHo', 'TriBeCa', 'Hudson Square', 'Little Italy', 'Chinatown', \n",
    "    'Cobble Hill', 'Carroll Gardens', 'Flatiron District', 'West Village', 'Chelsea', \n",
    "    'Downtown Brooklyn', 'Greenwood Heights', 'DUMBO', 'Boerum Hill', 'Williamsburg', \n",
    "    'Brooklyn Heights', 'Prospect Heights', 'Gowanus', 'Battery Park City', 'Upper East Side', \n",
    "    'Greenpoint', 'Upper West Side', 'Park Slope', 'Theatre District - Times Square', 'Central Midtown',\n",
    "    'Windsor Terrace', 'Hunters Point', 'Gramercy Park', 'Greenwich Village', 'Dyker Heights',\n",
    "    'Financial District', 'Belle Harbor', 'Lower East Side', 'Hollis Hills', 'Prospect - Lefferts Gardens',\n",
    "    'Madison', 'Little Neck', 'Clinton - Hell\\'s Kitchen', 'Auburndale', 'Fresh Meadows', \n",
    "    'Queensboro Hill', 'Crown Heights', 'Mill Basin', 'Ditmars - Steinway', 'East Village', \n",
    "    'Borough Park', 'Fieldston', 'Clinton Hill', 'Rockwood Park', 'Sutton Place', 'Fort Greene', 'NoMad', 'Nolita', 'Flatiron', \n",
    "    'Flatiron district','Midtown','Midtown East', 'NoLIta', 'Clinton', 'Dumbo', 'Koreatown', 'Midtown West', 'Times Square Theatre District',\n",
    "    'Union Square'\n",
    "    \n",
    "]\n",
    "\n",
    "df['Wealthy_Neighborhood'] = df['Neighborhood'].apply(lambda x: 1 if x in wealthy_neighborhoods else 0)\n",
    "\n",
    "\n",
    "model = smf.logit('top100_2024 ~ C(Wealthy_Neighborhood)', data = df)\n",
    "result = model.fit(method='bfgs', maxiter=100)\n",
    "print(result.summary())\n",
    "\n",
    "# Get the odds ratios\n",
    "odds_ratios = np.exp(result.params)\n",
    "print(\"Odds Ratios for Top Cuisine:\\n\", odds_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficient (Log Odds)</th>\n",
       "      <th>Odds Ratio</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Recent_Years</td>\n",
       "      <td>3.377294</td>\n",
       "      <td>29.291396</td>\n",
       "      <td>9.396031e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cuisine_French</td>\n",
       "      <td>1.886058</td>\n",
       "      <td>6.593329</td>\n",
       "      <td>1.080040e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cuisine_Eastern European</td>\n",
       "      <td>2.479280</td>\n",
       "      <td>11.932674</td>\n",
       "      <td>3.896341e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>College Graduates (%)</td>\n",
       "      <td>-8.154685</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>5.322105e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cuisine_Indian</td>\n",
       "      <td>1.849436</td>\n",
       "      <td>6.356236</td>\n",
       "      <td>1.031765e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cuisine_Korean</td>\n",
       "      <td>1.623567</td>\n",
       "      <td>5.071147</td>\n",
       "      <td>1.809921e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>College_Graduates_Group_Very Low</td>\n",
       "      <td>-1.591349</td>\n",
       "      <td>0.203651</td>\n",
       "      <td>2.382319e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Price_Categorical_Very Expensive</td>\n",
       "      <td>1.234624</td>\n",
       "      <td>3.437086</td>\n",
       "      <td>2.685521e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Master</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>3.878609e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Variable  Coefficient (Log Odds)  Odds Ratio  \\\n",
       "27                      Recent_Years                3.377294   29.291396   \n",
       "12                    Cuisine_French                1.886058    6.593329   \n",
       "11          Cuisine_Eastern European                2.479280   11.932674   \n",
       "37             College Graduates (%)               -8.154685    0.000287   \n",
       "14                    Cuisine_Indian                1.849436    6.356236   \n",
       "16                    Cuisine_Korean                1.623567    5.071147   \n",
       "45  College_Graduates_Group_Very Low               -1.591349    0.203651   \n",
       "3   Price_Categorical_Very Expensive                1.234624    3.437086   \n",
       "35                            Master               -0.000269    0.999731   \n",
       "\n",
       "         P-value  \n",
       "27  9.396031e-19  \n",
       "12  1.080040e-03  \n",
       "11  3.896341e-03  \n",
       "37  5.322105e-03  \n",
       "14  1.031765e-02  \n",
       "16  1.809921e-02  \n",
       "45  2.382319e-02  \n",
       "3   2.685521e-02  \n",
       "35  3.878609e-02  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df[summary_df['P-value']<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
